{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "import sys\n",
    "sys.path.append('/home/chenani/ownCloud/Workspaces/Eclipse/dataAnalysis/Sleep-current/src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenani/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: the sets module is deprecated\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from scipy.misc import comb\n",
    "import scipy as scp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pickle as pkl\n",
    "import sets\n",
    "import random\n",
    "import itertools\n",
    "import os,sys,fnmatch\n",
    "import timeit\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def subsequence(sub,ref):\n",
    "    '''\n",
    "    A function to determine the number of specefic sequence repeated within a larger sequence.\n",
    "    \n",
    "    Parameters:\n",
    "    sub:\n",
    "    ref:\n",
    "    \n",
    "    \n",
    "    Returns:\n",
    "    idx : This an array containing the index of elements of sub in the ref! if idx is stricktly increasing the sequence sub\n",
    "    is replayed whithin sequence ref!\n",
    "    '''\n",
    "    ref = np.array(ref)\n",
    "    idx = np.array([])\n",
    "    for ii in range(len(sub)):\n",
    "        index = np.where(ref == sub[ii])[0]\n",
    "        if index.size:\n",
    "            idx = np.append(idx,index)\n",
    "        else: \n",
    "            return [] , False\n",
    "    idx = np.int0(idx)\n",
    "    return idx, True\n",
    "\n",
    "def median(arr):\n",
    "    '''\n",
    "    mY median... ;)\n",
    "    '''\n",
    "    arr = np.array(arr)\n",
    "    if np.mod(arr.size,2) == 0 :\n",
    "        return arr[arr.size / 2 - 1]\n",
    "    else: \n",
    "        return arr[arr.size / 2 ]\n",
    "    \n",
    "def sequencer(arr,method = 'median'):\n",
    "    '''\n",
    "    This function sequences the given array(with possible repeated elements) into an array of distinct elements! Considering either \n",
    "    first or the midian position of repeated elements.\n",
    "    '''\n",
    "    arr = np.array(arr)\n",
    "    idx_seq = np.array([])\n",
    "    if method == 'median':\n",
    "        for item in set(arr):\n",
    "            idx_seq = np.append(idx_seq,median(np.where(arr == item)[0]))\n",
    "        idx_seq.sort()\n",
    "    if method == 'first':\n",
    "        for item in set(arr):\n",
    "            idx_seq = np.append(idx_seq,np.where(arr == item)[0][0])\n",
    "        idx_seq.sort()\n",
    "\n",
    "    return arr[np.int0(idx_seq)]\n",
    "\n",
    "def duplicate_indicator(arr_group,weights=np.array([])):\n",
    "    '''\n",
    "    Finds and counts the duplicates! This Function makes a frequency distribution the number of\n",
    "    arrays within a goup of arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    arr_group: The one that you want to count\n",
    "    weights: an array containig the wights(results of a previous counting of etc.). \n",
    "    If non empty the distribution will be weighted \n",
    "             with respect to this array!\n",
    "    Returns:\n",
    "    -----------\n",
    "    arr_set: Set of distinct arrays in arr_group\n",
    "    arr_weights: repitition counts of elements in arr_set.\n",
    "    '''\n",
    "    \n",
    "    arr_cp = np.copy(arr_group)   \n",
    "    for ii in range(len(arr_group)):\n",
    "        for jj in range(len(arr_group)):\n",
    "            if np.array_equal(arr_cp[jj], arr_cp[ii]) and ii != jj:\n",
    "                arr_cp[jj] = np.array([-1])\n",
    "    arr_set = []\n",
    "    for item in arr_cp:\n",
    "        if item.sum() > 0:\n",
    "            arr_set.append(item)\n",
    "    arr_set = np.array(arr_set)\n",
    "    ### Counting number of repititions\n",
    "    arr_weights = np.zeros(len(arr_set))\n",
    "    for ii in range(len(arr_set)):\n",
    "        for jj in range(len(arr_group)):\n",
    "            if np.array_equal(arr_group[jj],arr_set[ii]):\n",
    "                if weights.size:\n",
    "                    arr_weights[ii] += weights[jj]\n",
    "                else:\n",
    "                    arr_weights[ii] += 1\n",
    "    return arr_set,arr_weights\n",
    "\n",
    "def next_permutation(arr):\n",
    "    '''\n",
    "    \n",
    "        Computes the next lexicographical permutation of the specified list in place,\n",
    "     returning whether a next permutation existed. (Returns False when the argument\n",
    "     is already the last possible permutation.)\n",
    "    \n",
    "    \n",
    "         Example:\n",
    "            arr = [0, 1, 0]\n",
    "            next_permutation(arr)  (returns True)\n",
    "            arr has been modified to be [1, 0, 0]\n",
    "    Reference:\n",
    "    -----------\n",
    "    Nayuki Minase, 2014. Public domain.\n",
    "    http://nayuki.eigenstate.org/page/next-lexicographical-permutation-algorithm\n",
    "            '''\n",
    "    \n",
    "    i = len(arr) - 1\n",
    "    while i > 0 and arr[i - 1] >= arr[i]:\n",
    "        i -= 1\n",
    "    if i <= 0:\n",
    "        return False\n",
    "    \n",
    "    # Find successor to pivot\n",
    "    j = len(arr) - 1\n",
    "    while arr[j] <= arr[i - 1]:\n",
    "        j -= 1\n",
    "    arr[i - 1], arr[j] = arr[j], arr[i - 1]\n",
    "    \n",
    "    # Reverse suffix\n",
    "    arr[i : ] = arr[len(arr) - 1 : i - 1 : -1]\n",
    "    return True\n",
    "\n",
    "def number_of_permutations(arr):\n",
    "    Cnk = [] #keep the combinations!\n",
    "    s = 0    # sum of repitiotions of elements in arr!\n",
    "    arrcp = np.array(arr).copy()\n",
    "    arrcp.sort()\n",
    "    for item in set(arrcp):\n",
    "        reps = np.where(arrcp == item)[0].size\n",
    "        Cnk.append(comb(arrcp.size - s,reps,True))\n",
    "        s += reps\n",
    "    return np.prod(np.array(Cnk))\n",
    "-\n",
    "def All_permutations(arr):\n",
    "    '''\n",
    "    produces all possible permutations of a given array using lexographical ordering.\n",
    "    Sequence the arrays and returns the weights of all possible sequences!\n",
    "    This version is not using that much memory but its slow, better for long arrays.\n",
    "    written by A. Chenani Sep. 2014\n",
    "    '''\n",
    "    sqStack = []\n",
    "    weightsStack = []\n",
    "    for item in arr:\n",
    "        item.sort()\n",
    "        #####Cunstructing sequence set\n",
    "        arr_seqz_set = np.array([])\n",
    "        sample_seq = sequencer(item)\n",
    "        sample_seq.sort()\n",
    "        arr_seqz_set = np.append(arr_seqz_set,sample_seq)\n",
    "        while next_permutation(sample_seq):\n",
    "            arr_seqz_set = np.append(arr_seqz_set,sample_seq)\n",
    "        arr_seqz_set = arr_seqz_set.reshape(np.math.factorial(sample_seq.size),sample_seq.size)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #####creating MUA permutation list!\n",
    "        start =  timeit.default_timer()\n",
    "        lexRank = [0]\n",
    "        while next_permutation(item):\n",
    "            selection = np.arange(arr_seqz_set.size)\n",
    "            for ii in range(arr_seqz_set[0].size -1 ):\n",
    "                selection = np.intersect1d(selection,np.where(arr_seqz_set[:,ii]==sequencer(item)[ii])[0])\n",
    "            lexRank.append(selection[0])\n",
    "        lexRank = np.array(lexRank)\n",
    "        stop = timeit.default_timer()\n",
    "        print 'part two --> %f' %(stop - start)\n",
    "        #####Calculating the wights of all possible sequences\n",
    "        weights = []\n",
    "        for ii,item in enumerate(arr_seqz_set):\n",
    "            weights.append(np.where(lexRank == ii)[0].size /float(lexRank.size))\n",
    "        weightsStack.append(np.array(weights))\n",
    "        sqStack.append(arr_seqz_set)\n",
    "    return sqStack,weightsStack\n",
    "\n",
    "def locate(pattern, root=os.curdir):\n",
    "    '''Locate all files matching supplied filename pattern in and below\n",
    "        supplied root directory.\n",
    "    '''\n",
    "    for path, dirs, files in os.walk(os.path.abspath(root)):\n",
    "        for filename in fnmatch.filter(files, pattern):\n",
    "            yield [path,filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part one --> 0.024212\n",
      "part two --> 0.001847\n",
      "part three --> 0.000715\n"
     ]
    }
   ],
   "source": [
    "n = 4\n",
    "corr4 = np.array([])\n",
    "corr41 = np.array([])\n",
    "tempA = range(n)\n",
    "tempB = np.random.permutation(tempA)\n",
    "for item in all_permutations([range(n)])[0][0]:\n",
    "    c1 = scipy.stats.pearsonr(item,tempA)[0]\n",
    "    c2 = scipy.stats.pearsonr(item,tempB)[0]\n",
    "    LRcorr = np.array([c1,c2])\n",
    "    corr4  = np.append(corr4,LRcorr[np.argmax(np.abs(LRcorr))])\n",
    "    corr41 = np.append(corr41,c1)\n",
    "pkl.dump(corr41,open('./corr4.crr','wb'),pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(corr4,open('./corr4.crr2','wb'),pkl.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part one --> 0.013530\n",
      "part two --> 0.005834\n",
      "part three --> 0.002654\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "corr5 = np.array([])\n",
    "corr51 = np.array([])\n",
    "tempA = range(n)\n",
    "tempB = np.random.permutation(tempA)\n",
    "for item in all_permutations([range(n)])[0][0]:\n",
    "    c1 = scipy.stats.pearsonr(item,tempA)[0]\n",
    "    c2 = scipy.stats.pearsonr(item,tempB)[0]\n",
    "    LRcorr = np.array([c1,c2])\n",
    "    corr5 = np.append(corr5,LRcorr[np.argmax(np.abs(LRcorr))])\n",
    "    corr51 = np.append(corr51,c1)\n",
    "pkl.dump(corr51,open('./corr5.crr','wb'),pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(corr5,open('./corr5.crr2','wb'),pkl.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part one --> 0.033817\n",
      "part two --> 0.049252\n",
      "part three --> 0.021060\n"
     ]
    }
   ],
   "source": [
    "n = 6\n",
    "corr6 = np.array([])\n",
    "corr61 = np.array([])\n",
    "tempA = range(n)\n",
    "tempB = np.random.permutation(tempA)\n",
    "for item in all_permutations([range(n)])[0][0]:\n",
    "    c1 = scipy.stats.pearsonr(item,tempA)[0]\n",
    "    c2 = scipy.stats.pearsonr(item,tempB)[0]\n",
    "    LRcorr = np.array([c1,c2])\n",
    "    corr6 = np.append(corr6,LRcorr[np.argmax(np.abs(LRcorr))])\n",
    "    corr61 = np.append(corr61,c1)\n",
    "pkl.dump(corr61,open('./corr6.crr','wb'),pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(corr6,open('./corr6.crr2','wb'),pkl.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part one --> 0.110976\n",
      "part two --> 0.298297\n",
      "part three --> 0.330161\n"
     ]
    }
   ],
   "source": [
    "n = 7\n",
    "corr7 = np.array([])\n",
    "corr71 = np.array([])\n",
    "tempA = range(n)\n",
    "tempB = np.random.permutation(tempA)\n",
    "for item in all_permutations([range(n)])[0][0]:\n",
    "    c1 = scipy.stats.pearsonr(item,tempA)[0]\n",
    "    c2 = scipy.stats.pearsonr(item,tempB)[0]\n",
    "    LRcorr = np.array([c1,c2])\n",
    "    corr7 = np.append(corr7,LRcorr[np.argmax(np.abs(LRcorr))])\n",
    "    corr71 = np.append(corr71,c1)\n",
    "pkl.dump(corr71,open('./corr7.crr','wb'),pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(corr7,open('./corr7.crr2','wb'),pkl.HIGHEST_PROTOCOL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part one --> 6.445822\n",
      "part two --> 2.639297\n",
      "part three --> 11.726598\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "corr8 = np.array([])\n",
    "corr81 = np.array([])\n",
    "tempA = range(n)\n",
    "tempB = np.random.permutation(tempA)\n",
    "for item in all_permutations([range(n)])[0][0]:\n",
    "    c1 = scipy.stats.pearsonr(item,tempA)[0]\n",
    "    c2 = scipy.stats.pearsonr(item,tempB)[0]\n",
    "    LRcorr = np.array([c1,c2])\n",
    "    corr8 = np.append(corr8,LRcorr[np.argmax(np.abs(LRcorr))])\n",
    "    corr81 = np.append(corr81,c1)\n",
    "pkl.dump(corr81,open('./corr8.crr','wb'),pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(corr8,open('./corr8.crr2','wb'),pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part one --> 638.572554\n",
      "part two --> 27.515902\n",
      "part three --> 1250.159629\n"
     ]
    }
   ],
   "source": [
    "n=9\n",
    "A = range(n)\n",
    "corr9 = np.array([])\n",
    "corr91 = np.array([])\n",
    "tempA = range(n)\n",
    "tempB = np.random.permutation(tempA)\n",
    "for item in all_permutations([range(n)])[0][0]:\n",
    "    c1 = scipy.stats.pearsonr(item,tempA)[0]\n",
    "    c2 = scipy.stats.pearsonr(item,tempB)[0]\n",
    "    LRcorr = np.array([c1,c2])\n",
    "    corr9  = np.append(corr9,LRcorr[np.argmax(np.abs(LRcorr))])\n",
    "    corr91 = np.append(corr91,c1)\n",
    "pkl.dump(corr91,open('./corr9.crr','wb'),pkl.HIGHEST_PROTOCOL)\n",
    "pkl.dump(corr9,open('./corr9.crr2','wb'),pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
