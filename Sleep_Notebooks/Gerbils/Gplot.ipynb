{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt4Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/mnt/Data/ownCloud/Workspaces/Eclipse/dataAnalysis/Sleep-current/src/\")\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenani/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "/home/chenani/anaconda/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/home/chenani/anaconda/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import pickle as pkl\n",
    "import colormaps as mycmps\n",
    "import signale.tools as tools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib as mpl\n",
    "import scipy.signal as scsig\n",
    "from scipy.stats import sem\n",
    "from matplotlib import rcParams\n",
    "import trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet Analysis Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A module which implements the continuous wavelet transform\n",
    "\n",
    "---------------------------------------------------------\n",
    "Code released under the BSD 3-clause licence.\n",
    "\n",
    "Copyright (c) 2012, R W Fearick, University of Cape Town\n",
    "All rights reserved.\n",
    "\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the\n",
    "following conditions are met:\n",
    "\n",
    "    * Redistributions of source code must retain the above copyright notice, this list of conditions and\n",
    "        the following disclaimer.\n",
    "    * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and\n",
    "        the following disclaimer in the documentation and/or other materials provided with the distribution.\n",
    "    * Neither the name of the University of Cape Town nor the names of its contributors may be used to endorse\n",
    "        or promote products derived from this software without specific prior written permission.\n",
    "\n",
    "THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, \n",
    "INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE\n",
    "DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
    "SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR \n",
    "SERVICES;LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n",
    "WHETHER IN CONTRACT,STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE\n",
    "USE OF THIS SOFTWARE,EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "---------------------------------------------------------\n",
    "\n",
    "Wavelet classes:\n",
    "Morlet\n",
    "MorletReal\n",
    "MexicanHat\n",
    "Paul2      : Paul order 2\n",
    "Paul4      : Paul order 4\n",
    "DOG1       : 1st Derivative Of Gaussian\n",
    "DOG4       : 4th Derivative Of Gaussian\n",
    "Haar       : Unnormalised version of continuous Haar transform\n",
    "HaarW      : Normalised Haar\n",
    "\n",
    "Usage e.g.\n",
    "wavelet=Morlet(data, largestscale=2, notes=0, order=2, scaling=\"log\")\n",
    " data:  Numeric array of data (float), with length ndata.\n",
    "        Optimum length is a power of 2 (for FFT)\n",
    "        Worst-case length is a prime\n",
    " largestscale:\n",
    "        largest scale as inverse fraction of length\n",
    "        scale = len(data)/largestscalax1.set_xticklabels([e\n",
    "        smallest scale should be >= 2 for meaningful data\n",
    " notes: number of scale intervals per octave\n",
    "        if notes == 0, scales are on a linear increment\n",
    " order: order of wavelet for wavelets with variable order\n",
    "        [Paul, DOG, ..]\n",
    " scaling: \"linear\" or \"log\" scaling of the wavelet scale.\n",
    "        Note that feature width in the scale direction\n",
    "        is constant on a log scale.\n",
    "        \n",
    "Attributes of instance:\n",
    "wavelet.cwt:       2-d array of Wavelet coefficients, (nscales,ndata)\n",
    "wavelet.nscale:    Number of scale intervals\n",
    "wavelet.scales:    Array of scale values\n",
    "                   Note that meaning of the scale will depend on the family\n",
    "wavelet.fourierwl: Factor to multiply scale by to get scale\n",
    "                   of equivalent FFT\n",
    "                   Using this factor, different wavelet families will\n",
    "                   have comparable scales\n",
    "\n",
    "References:\n",
    "A practical guide to wavelet analysis\n",
    "C Torrance and GP Compo\n",
    "Bull Amer Meteor Soc Vol 79 No 1 61-78 (1998)\n",
    "naming below vaguely follows this.\n",
    "\n",
    "updates:\n",
    "(24/2/07):  Fix Morlet so can get MorletReal by cutting out H\n",
    "(10/04/08): Numeric -> numpy\n",
    "(25/07/08): log and lin scale increment in same direction!\n",
    "            swap indices in 2-d coeffiecient matrix\n",
    "            explicit scaling of scale axis\n",
    "\"\"\"\n",
    "\n",
    "class Cwt:\n",
    "    \"\"\"\n",
    "    Base class for continuous wavelet transforms\n",
    "    Implements cwt via the Fourier transform\n",
    "    Used by subclass which provides the method wf(self,s_omega)\n",
    "    wf is the Fourier transform of the wavelet function.\n",
    "    Returns an instance.\n",
    "    \"\"\"\n",
    "\n",
    "    fourierwl=1.00\n",
    "\n",
    "    def _log2(self, x):\n",
    "        # utility function to return (integer) log2\n",
    "        return int( np.log(float(x))/ np.log(2.0)+0.0001 )\n",
    "\n",
    "    def __init__(self, data, largestscale=1, notes=0, order=2, scaling='linear'):\n",
    "        \"\"\"\n",
    "        Continuous wavelet transform of data\n",
    "\n",
    "        data:    data in array to transform, length must be power of 2\n",
    "        notes:   number of scale intervals per octave\n",
    "        largestscale: largest scale as inverse fraction of length\n",
    "                 of data array\n",
    "                 scale = len(data)/largestscale\n",
    "                 smallest scale should be >= 2 for meaningful data\n",
    "        order:   Order of wavelet basis function for some families\n",
    "        scaling: Linear or log\n",
    "        \"\"\"\n",
    "        ndata = len(data)\n",
    "        self.order=order\n",
    "        self.scale=largestscale\n",
    "        self._setscales(ndata,largestscale,notes,scaling)\n",
    "        self.cwt= np.zeros((self.nscale,ndata), np.complex64)\n",
    "        omega= np.array(range(0,ndata/2)+range(-ndata/2,0))*(2.0*np.pi/ndata)\n",
    "        datahat=np.fft.fft(data)\n",
    "        self.fftdata=datahat\n",
    "        #self.psihat0=self.wf(omega*self.scales[3*self.nscale/4])\n",
    "        # loop over scales and compute wvelet coeffiecients at each scale\n",
    "        # using the fft to do the convolution\n",
    "        for scaleindex in range(self.nscale):\n",
    "            currentscale=self.scales[scaleindex]\n",
    "            self.currentscale=currentscale  # for internal use\n",
    "            s_omega = omega*currentscale\n",
    "            psihat=self.wf(s_omega)\n",
    "            psihat = psihat *  np.sqrt(2.0*np.pi*currentscale)\n",
    "            convhat = psihat * datahat\n",
    "            W    = np.fft.ifft(convhat)\n",
    "            self.cwt[scaleindex,0:ndata] = W \n",
    "        return\n",
    "    \n",
    "    def _setscales(self,ndata,largestscale,notes,scaling):\n",
    "        \"\"\"\n",
    "        if notes non-zero, returns a log scale based on notes per ocave\n",
    "        else a linear scale\n",
    "        (25/07/08): fix notes!=0 case so smallest scale at [0]\n",
    "        \"\"\"\n",
    "        if scaling==\"log\":\n",
    "            if notes<=0: notes=1 \n",
    "            # adjust nscale so smallest scale is 2 \n",
    "            noctave=self._log2( ndata/largestscale/2 )\n",
    "            self.nscale=notes*noctave\n",
    "            self.scales=np.zeros(self.nscale,float)\n",
    "            for j in range(self.nscale):\n",
    "                self.scales[j] = ndata/(self.scale*(2.0**(float(self.nscale-1-j)/notes)))\n",
    "        elif scaling==\"linear\":\n",
    "            nmax=ndata/largestscale/2\n",
    "            self.scales=np.arange(float(2),float(nmax))\n",
    "            self.nscale=len(self.scales)\n",
    "        else: raise ValueError, \"scaling must be linear or log\"\n",
    "        return\n",
    "    \n",
    "    def getdata(self):\n",
    "        \"\"\"\n",
    "        returns wavelet coefficient array\n",
    "        \"\"\"\n",
    "        return self.cwt\n",
    "    def getcoefficients(self):\n",
    "        return self.cwt\n",
    "    def getpower(self):\n",
    "        \"\"\"\n",
    "        returns square of wavelet coefficient array\n",
    "        \"\"\"\n",
    "        return (self.cwt* np.conjugate(self.cwt)).real\n",
    "    def getscales(self):\n",
    "        \"\"\"\n",
    "        returns array containing scales used in transform\n",
    "        \"\"\"\n",
    "        return self.scales\n",
    "    def getnscale(self):\n",
    "        \"\"\"\n",
    "        return number of scales\n",
    "        \"\"\"\n",
    "        return self.nscale\n",
    "\n",
    "# wavelet classes    \n",
    "class Morlet(Cwt):\n",
    "    \"\"\"\n",
    "    Morlet wavelet\n",
    "    \"\"\"\n",
    "    _omega0=6.0\n",
    "    fourierwl=4* np.pi/(_omega0+ np.sqrt(2.0+_omega0**2))\n",
    "    def wf(self, s_omega):\n",
    "        H= np.ones(len(s_omega))\n",
    "        n=len(s_omega)\n",
    "        for i in range(len(s_omega)):\n",
    "            if s_omega[i] < 0.0: H[i]=0.0\n",
    "        # !!!! note : was s_omega/8 before 17/6/03\n",
    "        xhat=0.75112554*( np.exp(-(s_omega-self._omega0)**2/2.0))*H\n",
    "        return xhat\n",
    "\n",
    "class MorletReal(Cwt):\n",
    "    \"\"\"\n",
    "    Real Morlet wavelet\n",
    "    \"\"\"\n",
    "    _omega0=5.0\n",
    "    fourierwl=4* np.pi/(_omega0+ np.sqrt(2.0+_omega0**2))\n",
    "    def wf(self, s_omega):\n",
    "        H= np.ones(len(s_omega))\n",
    "        n=len(s_omega)\n",
    "        for i in range(len(s_omega)):\n",
    "            if s_omega[i] < 0.0: H[i]=0.0\n",
    "        # !!!! note : was s_omega/8 before 17/6/03\n",
    "        xhat=0.75112554*( np.exp(-(s_omega-self._omega0)**2/2.0)\n",
    "                         + np.exp(-(s_omega+self._omega0)**2/2.0)\n",
    "                         - np.exp(-(self._omega0)**2/2.0)\n",
    "                         + np.exp(-(self._omega0)**2/2.0))\n",
    "        return xhat\n",
    "    \n",
    "class Paul4(Cwt):\n",
    "    \"\"\"\n",
    "    Paul m=4 wavelet\n",
    "    \"\"\"\n",
    "    fourierwl=4* np.pi/(2.*4+1.)\n",
    "    def wf(self, s_omega):\n",
    "        n=len(s_omega)\n",
    "        xhat= np.zeros(n)\n",
    "        xhat[0:n/2]=0.11268723*s_omega[0:n/2]**4* np.exp(-s_omega[0:n/2])\n",
    "        #return 0.11268723*s_omega**2*exp(-s_omega)*H\n",
    "        return xhat\n",
    "\n",
    "class Paul2(Cwt):\n",
    "    \"\"\"\n",
    "    Paul m=2 wavelet\n",
    "    \"\"\"\n",
    "    fourierwl=4* np.pi/(2.*2+1.)\n",
    "    def wf(self, s_omega):\n",
    "        n=len(s_omega)\n",
    "        xhat= np.zeros(n)\n",
    "        xhat[0:n/2]=1.1547005*s_omega[0:n/2]**2* np.exp(-s_omega[0:n/2])\n",
    "        #return 0.11268723*s_omega**2*exp(-s_omega)*H\n",
    "        return xhat\n",
    "\n",
    "class Paul(Cwt):\n",
    "    \"\"\"\n",
    "    Paul order m wavelet\n",
    "    \"\"\"\n",
    "    def wf(self, s_omega):\n",
    "        Cwt.fourierwl=4* np.pi/(2.*self.order+1.)\n",
    "        m=self.order\n",
    "        n=len(s_omega)\n",
    "        normfactor=float(m)\n",
    "        for i in range(1,2*m):\n",
    "            normfactor=normfactor*i\n",
    "        normfactor=2.0**m/ np.sqrt(normfactor)\n",
    "        xhat= np.zeros(n)\n",
    "        xhat[0:n/2]=normfactor*s_omega[0:n/2]**m* np.exp(-s_omega[0:n/2])\n",
    "        #return 0.11268723*s_omega**2*exp(-s_omega)*H\n",
    "        return xhat\n",
    "\n",
    "class MexicanHat(Cwt):\n",
    "    \"\"\"\n",
    "    2nd Derivative Gaussian (mexican hat) wavelet\n",
    "    \"\"\"\n",
    "    fourierwl=2.0* np.pi/ np.sqrt(2.5)\n",
    "    def wf(self, s_omega):\n",
    "        # should this number be 1/sqrt(3/4) (no pi)?\n",
    "        #s_omega = s_omega/self.fourierwl\n",
    "        #print max(s_omega)\n",
    "        a=s_omega**2\n",
    "        b=s_omega**2/2\n",
    "        return a* np.exp(-b)/1.1529702\n",
    "        #return s_omega**2*exp(-s_omega**2/2.0)/1.1529702\n",
    "\n",
    "class DOG4(Cwt):\n",
    "    \"\"\"\n",
    "    4th Derivative Gaussian wavelet\n",
    "    see also T&C errata for - sign\n",
    "    but reconstruction seems to work best with +!\n",
    "    \"\"\"\n",
    "    fourierwl=2.0* np.pi/ np.sqrt(4.5)\n",
    "    def wf(self, s_omega):\n",
    "        return s_omega**4* np.exp(-s_omega**2/2.0)/3.4105319\n",
    "\n",
    "class DOG1(Cwt):\n",
    "    \"\"\"\n",
    "    1st Derivative Gaussian wavelet\n",
    "    but reconstruction seems to work best with +!\n",
    "    \"\"\"\n",
    "    fourierwl=2.0* np.pi/ np.sqrt(1.5)\n",
    "    def wf(self, s_omega):\n",
    "        dog1= np.zeros(len(s_omega),complex64)\n",
    "        dog1.imag=s_omega* np.exp(-s_omega**2/2.0)/sqrt(pi)\n",
    "        return dog1\n",
    "\n",
    "class DOG(Cwt):\n",
    "    \"\"\"\n",
    "    Derivative Gaussian wavelet of order m\n",
    "    but reconstruction seems to work best with +!\n",
    "    \"\"\"\n",
    "    def wf(self, s_omega):\n",
    "        try:\n",
    "            from scipy.special import gamma\n",
    "        except ImportError:\n",
    "            print \"Requires scipy gamma function\"\n",
    "            raise ImportError\n",
    "        Cwt.fourierwl=2* np.pi/ np.sqrt(self.order+0.5)\n",
    "        m=self.order\n",
    "        dog=1.0J**m*s_omega**m* np.exp(-s_omega**2/2)/ np.sqrt(gamma(self.order+0.5))\n",
    "        return dog\n",
    "\n",
    "class Haar(Cwt):\n",
    "    \"\"\"\n",
    "    Continuous version of Haar wavelet\n",
    "    \"\"\"\n",
    "    #    note: not orthogonal!\n",
    "    #    note: s_omega/4 matches Lecroix scale defn.\n",
    "    #          s_omega/2 matches orthogonal Haar\n",
    "    # 2/8/05 constants adjusted to match artem eim\n",
    "\n",
    "    fourierwl=1.0#1.83129  #2.0\n",
    "    def wf(self, s_omega):\n",
    "        haar= np.zeros(len(s_omega),complex64)\n",
    "        om = s_omega[:]/self.currentscale\n",
    "        om[0]=1.0  #prevent divide error\n",
    "        #haar.imag=4.0*sin(s_omega/2)**2/om\n",
    "        haar.imag=4.0* np.sin(s_omega/4)**2/om\n",
    "        return haar\n",
    "\n",
    "class HaarW(Cwt):\n",
    "    \"\"\"\n",
    "    Continuous version of Haar wavelet (norm)\n",
    "    \"\"\"\n",
    "    #    note: not orthogonal!\n",
    "    #    note: s_omega/4 matches Lecroix scale defn.\n",
    "    #          s_omega/2 matches orthogonal Haar\n",
    "    # normalised to unit power\n",
    "\n",
    "    fourierwl=1.83129*1.2  #2.0\n",
    "    def wf(self, s_omega):\n",
    "        haar= np.zeros(len(s_omega),complex64)\n",
    "        om = s_omega[:]#/self.currentscale\n",
    "        om[0]=1.0  #prevent divide error\n",
    "        #haar.imag=4.0*sin(s_omega/2)**2/om\n",
    "        haar.imag=4.0* np.sin(s_omega/2)**2/om\n",
    "        return haar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/Data/data/Gerbils/G5/data/2011-08-04_sleep1_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-04_sleep2_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-04_sleep3_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-05_sleep1_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-05_sleep2_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-05_sleep3_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-07_sleep1_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-07_sleep2_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-07_sleep3_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-09_sleep1_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-09_sleep2_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-09_sleep3_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-10_sleep1_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-10_sleep2_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-10_sleep3_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-14_sleep1_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-14_sleep2_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-14_sleep3_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-15_sleep1_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G5/data/2011-08-15_sleep2_csc4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G6/2011-09-19/2011-09-19_sleep1_CSC4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G6/2011-09-19/2011-09-19_sleep2_CSC4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G6/2011-09-19/2011-09-19_sleep3_CSC4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G6/2011-09-23/2011-09-23_sleep1_CSC4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G6/2011-09-23/2011-09-23_sleep2_CSC4.lfp',\n",
       " '/mnt/Data/data/Gerbils/G6/2011-09-23/2011-09-23_sleep3_CSC4.lfp']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animalPath = '/mnt/Data/data/Gerbils/'\n",
    "localPath = '/mnt/Data/'\n",
    "lfpPaths = []\n",
    "for lfp in tools.locate('*.lfp',animalPath):\n",
    "    lfpPaths.append(os.path.join(lfp[0],lfp[1]))\n",
    "lfpPaths = sorted(lfpPaths)\n",
    "lfpPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colors & Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "colors = [\"windows blue\", \"amber\", \"greyish\", \"faded green\", \"dusty purple\"]\n",
    "seabC = sns.xkcd_palette(colors)\n",
    "seabP = sns.color_palette(\"Paired\")\n",
    "#sns.palplot(seabP)\n",
    "#sns.palplot(sns.xkcd_palette(colors))\n",
    "sns.set_style(\"ticks\")\n",
    "rcParams['xtick.direction'] = 'in'\n",
    "rcParams['ytick.direction'] = 'in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic lyout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure = pl.figure(figsize = [15,10])\n",
    "gs1 = gridspec.GridSpec(2, 1)\n",
    "gs1.update(left=0.1, right=0.48,bottom=0.5, wspace=0.05)\n",
    "ax0 = pl.subplot(gs1[0,:])\n",
    "ax1 = pl.subplot(gs1[1, :])\n",
    "ax0.xaxis.tick_bottom()\n",
    "ax0.yaxis.tick_left()\n",
    "ax1.xaxis.tick_bottom()\n",
    "ax1.yaxis.tick_left()\n",
    "gs3 = gridspec.GridSpec(3, 4)\n",
    "gs3.update(left=0.06, right=0.475,top=0.39, wspace=0.05,hspace=0.01)\n",
    "ax2 = pl.subplot(gs3[1:,0])\n",
    "ax2up = pl.subplot(gs3[0,0])\n",
    "#ax2p = ax2.twinx()\n",
    "#ax2p.axes.get_yaxis().set_ticks([])\n",
    "ax3 = pl.subplot(gs3[1:,1])\n",
    "ax3up = pl.subplot(gs3[0,1])\n",
    "#ax3p = ax3.twinx()\n",
    "#ax3p.axes.get_yaxis().set_ticks([])\n",
    "ax3.axes.get_yaxis().set_ticks([])\n",
    "ax4 = pl.subplot(gs3[1:,2])\n",
    "ax4up = pl.subplot(gs3[0,2])\n",
    "#ax4p = ax4.twinx()\n",
    "#ax4p.axes.get_yaxis().set_ticks([])\n",
    "ax4.axes.get_yaxis().set_ticks([])\n",
    "ax5 = pl.subplot(gs3[1:,3])\n",
    "ax5up = pl.subplot(gs3[0,3])\n",
    "#ax5p = ax5.twinx()\n",
    "#ax5p.axes.get_yaxis().set_ticks([])\n",
    "ax5.axes.get_yaxis().set_ticks([])\n",
    "#ax6 = pl.subplot(gs1[-1,0])\n",
    "#ax7 = pl.subplot(gs1[-1,1])\n",
    "#ax8 = pl.subplot(gs1[-1,2])\n",
    "#ax9 = pl.subplot(gs1[-1,3])\n",
    "axarr = [ax1,ax2,ax3,ax4,ax5]\n",
    "gs1.tight_layout(figure,rect=[0, 0.5, 0.5, 1])\n",
    "for axxx in axarr:\n",
    "    axxx.xaxis.tick_bottom()\n",
    "    axxx.yaxis.tick_left()\n",
    "#gs3.tight_layout(figure,rect=[0.0, 0, 0.5, 0.33])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sleep phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SleepEpochs = pd.read_pickle(animalPath+'SleepEpochs.pd')\n",
    "df = pd.read_pickle(animalPath+'psdData.pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113.170212766 25 405\n",
      "107.833333333 20 400\n"
     ]
    }
   ],
   "source": [
    "remEP = SleepEpochs[SleepEpochs.epoch=='REM']\n",
    "swsEP = SleepEpochs[SleepEpochs.epoch=='SWS']\n",
    "print (remEP.t1-remEP.t0).mean(), (remEP.t1-remEP.t0).min(), (remEP.t1-remEP.t0).max()\n",
    "print (swsEP.t1-swsEP.t0).mean(),(swsEP.t1-swsEP.t0).min(),(swsEP.t1-swsEP.t0).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lfp = pkl.load(open('/mnt/Data/data/Gerbils/G5/data/2011-08-07_sleep2_csc4.lfp','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading /mnt/Data/data/Gerbils/G5/data/2011-08-07/sleep2/VT1.nvt\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/Data/data/Gerbils/G5/data/2011-08-07/sleep2/VT1.nvt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-074bcf4144e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mHDtraj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m        \u001b[1;31m# head direction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtraj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m          \u001b[1;31m# trajectory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgetTraj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/mnt/Data/data/Gerbils/G5/data/2011-08-07/sleep2/VT1.nvt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-074bcf4144e2>\u001b[0m in \u001b[0;36mgetTraj\u001b[1;34m(trajFile)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mHDtraj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[1;34m'loading'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrajFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtraj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrajectory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_nvtFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrajFile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'linearMaze'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshowHeader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mHDtraj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m        \u001b[1;31m# head direction\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtraj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraj\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m          \u001b[1;31m# trajectory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/Data/ownCloud/Workspaces/Eclipse/dataAnalysis/Sleep-current/src/trajectory/io.pyc\u001b[0m in \u001b[0;36mload_nvtFile\u001b[1;34m(fileName, mazeType, showHeader)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0meulSamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mheader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# the first 16 kB are an ASCII text header\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/mnt/Data/data/Gerbils/G5/data/2011-08-07/sleep2/VT1.nvt'"
     ]
    }
   ],
   "source": [
    "traj = None\n",
    "HDtraj = None\n",
    "def getTraj(trajFile):\n",
    "    global traj\n",
    "    global HDtraj\n",
    "    print 'loading', trajFile\n",
    "    traj = trajectory.load_nvtFile(trajFile, 'linearMaze', showHeader=False)\n",
    "    HDtraj = traj[1]        # head direction\n",
    "    traj = traj[0]          # trajectory\n",
    "getTraj('/mnt/Data/data/Gerbils/G5/data/2011-08-07/sleep2/VT1.nvt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'times'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-52140aa4b8c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtraj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m1e3\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'times'"
     ]
    }
   ],
   "source": [
    "traj.times[-1]-traj.times[0],lfp.duration()/1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-ffe981dd92a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Pxx' is not defined"
     ]
    }
   ],
   "source": [
    "Pxx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'spectrogram'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-822384d0f831>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mPxx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminFreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxFreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moverlap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindowSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhiten\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mBandAvg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mPxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscsig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgaussian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mBandAvg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPxx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'spectrogram'"
     ]
    }
   ],
   "source": [
    "Pxx, freqs, t = lfp.spectrogram(minFreq=.1,maxFreq=55,overlap=1024,windowSize=2048,whiten=True)\n",
    "BandAvg = []\n",
    "for col in range(Pxx.shape[1]):\n",
    "    Pxx[:,col] = np.convolve(Pxx[:,col],scsig.gaussian(10,3),'same')\n",
    "    BandAvg.append(np.array([np.average(Pxx[:,col][0:15]),np.average(Pxx[:,col][16:31]),np.average(Pxx[:,col][32:])]))\n",
    "for row in range(Pxx.shape[0]):\n",
    "    Pxx[row,:] = np.convolve(Pxx[row,:],scsig.gaussian(20,5),'same')\n",
    "Pxx = np.clip(Pxx,0,Pxx.mean()+1.4*Pxx.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#im = ax0.pcolormesh(t/1000.0,freqs,Pxx,cmap=mycmps.viridis)\n",
    "im = ax0.imshow(Pxx,aspect='auto',cmap='viridis')\n",
    "ax0.axvspan(168,730,color='w',alpha=0.3)\n",
    "#ax0.axvspan(790,900,color=seabC[1],alpha=0.3)\n",
    "#ax0.axvspan(1430,1610,color=seabC[1],alpha=0.3)\n",
    "#ax0.axhline(5,c='w',lw=0.5)\n",
    "ax0.set_xlim(0,1000)\n",
    "#ax0.set_xticks([0,200,400,600,800,1000])\n",
    "#ax0.set_xticklabels(['0','100','200','300','400','500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax0.cla()\n",
    "ax1.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pwr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-01869244b65a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpwr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pwr' is not defined"
     ]
    }
   ],
   "source": [
    "sfig,axx = pl.subplots(1,1)\n",
    "axx.imshow(pwr,aspect='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0fb8b9df90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ax1.set_yscale('log')\n",
    "colList = [seabP[0],seabP[2]]\n",
    "decIdx = df.index[::35]\n",
    "dfsub = df.loc[decIdx]\n",
    "dfbelow = dfsub[dfsub.f < 56.5]\n",
    "dfabove = dfsub[dfsub.f > 62.5]\n",
    "#sns.tsplot(value='psd',time='f',condition='epoch',unit='epochNo',data=dfbelow,ax=ax1,color=colList)\n",
    "sns.tsplot(value='psd',time='f',condition='epoch',unit='epochNo',data=df,ax=ax1,color=colList,legend=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax1.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax0.set_yticks([10,20,30,40,50,159])\n",
    "ax0.set_yticklabels([r'4',r'8',r'12',r'16',r'20'],fontsize=14)\n",
    "ax0.set_xlabel('Time (s)',fontsize=14)\n",
    "ax0.set_xticklabels([r'0',r'100',r'200',r'300',r'400',r'500',r'600'],fontsize=14)\n",
    "ax0.set_ylabel('Frequency (Hz)',fontsize=14)\n",
    "ax0.set_ylim(0.3,170)\n",
    "ax1.set_xlabel('Frequency (Hz)',fontsize=14)\n",
    "#ax1.set_xticklabels([0,50,100,150,200,250],fontsize=14)\n",
    "ax1.set_ylabel('Power (dB)',fontsize=14)\n",
    "ax1.set_xticklabels([r'0',r'50',r'100',r'150',r'200',r'250'],fontsize=14)\n",
    "ax1.set_yticks([])\n",
    "ax1.set_yticklabels([])\n",
    "ax1.set_xlim([0,250])\n",
    "ax1.set_ylim([5e7,3.1e8])\n",
    "ax1.legend(loc=4)\n",
    "#ax2.set_axis_off()\n",
    "gs1.tight_layout(figure,rect=[0, 0.4, 0.5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ripple Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rippDB = pd.read_pickle(animalPath+'RipplesTimeDB.pd')\n",
    "c  = np.int16(np.loadtxt('/mnt/Data/data/Gerbils/pink.clu.1'))[1:]\n",
    "wc = np.int16(np.loadtxt('/mnt/Data/data/Gerbils/white.clu.1'))[1:]\n",
    "np.place(wc,wc==3,[1])\n",
    "np.place(c,c==2,[1])\n",
    "np.place(c,c==3,[2])\n",
    "rippDB['wc'] = wc\n",
    "rippDB['c'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(470, 24) (5201, 24)\n",
      "['2011-08-05' '2011-08-07' '2011-08-09' '2011-08-10' '2011-09-19'\n",
      " '2011-09-23']\n",
      "26\n",
      "(14481, 24)\n",
      "(2339, 24) (10674, 24)\n"
     ]
    }
   ],
   "source": [
    "print selS[selS.epoch=='rem'].shape,selG[selG.epoch=='rem'].shape\n",
    "print np.unique(rippDB.date)\n",
    "print len(lfpPaths)\n",
    "print rippDB.shape\n",
    "print selS.shape,selG.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swrEx = np.logical_and(np.logical_and(rippDB.HilbertAbsPeak>-5.9,rippDB.c==1),rippDB.wc==1).as_matrix()\n",
    "gbsEx = np.logical_and(np.logical_and(rippDB.HilbertAbsPeak>-8.9,rippDB.c==2),rippDB.wc==2).as_matrix()\n",
    "selS = rippDB.loc[swrEx]\n",
    "selG = rippDB.loc[gbsEx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fiz = pl.figure(figsize=[4,6])\n",
    "bx = pl.Axes(fiz, [0., 0., 1., 1.])\n",
    "bx.set_axis_off()\n",
    "fiz.add_axes(bx)\n",
    "cxx = bx.twinx()\n",
    "pl.axis('off')\n",
    "wavelet=Morlet\n",
    "maxscale=3.05\n",
    "notes=64\n",
    "scaling=\"log\" #or \"linear\"\n",
    "#scaling=\"linear\"\n",
    "plotpower2d=True\n",
    "# set up some data\n",
    "Ns=2000\n",
    "for kk,item in enumerate(selS[selS.epoch=='rem'].index):\n",
    "    if kk>-460:\n",
    "        for path in lfpPaths:\n",
    "            session = selS.session[item].split('0')[0]+selS.session[item].split('0')[1]\n",
    "            if path.find(selS.date[item])>0 and path.find(session)>0:\n",
    "                lfp = pkl.load(open(path,'rb'))\n",
    "                tP = selS['t_peak'][item]\n",
    "                t1 = tools.findNearest(lfp.timeAxis,tP-256)[0]\n",
    "                t2 = tools.findNearest(lfp.timeAxis,tP+256)[0]\n",
    "                sig = lfp.signal[t1:t2]\n",
    "                wsig = lfp.signal_white[t1:t2]\n",
    "                cw=wavelet(wsig,maxscale,notes,scaling=scaling)\n",
    "                scales=cw.getscales()     \n",
    "                cwt=cw.getdata()\n",
    "                # power spectrum\n",
    "                pwr=cw.getpower()\n",
    "                scalespec=np.sum(pwr,axis=1)/scales # calculate scale spectrum\n",
    "                # scales\n",
    "                y=cw.fourierwl*scales\n",
    "                for jj in range(pwr.shape[1]):\n",
    "                    pwr[:,jj] = np.convolve(pwr[:,jj],scsig.gaussian(15,15),'same')\n",
    "                bx.pcolormesh(np.linspace(-0.512,0.512,1024),y[::-1],(pwr),cmap = mycmps.magma)\n",
    "                bx.axhline(150,linewidth='1.5',color = 'w',linestyle='--')\n",
    "                bx.set_xlim(-0.3,0.3)\n",
    "                bx.set_ylim(4,250)\n",
    "                #bx.set_axis_off()\n",
    "                cxx.set_aspect('auto')\n",
    "                #ax4up.plot(np.linspace(-0.512,0.512,1024),sig,c='k',lw=0.9,alpha=0.000085)\n",
    "                cxx.plot(np.linspace(-0.512,0.512,1024),sig,c='w',lw=1.0)\n",
    "                cxx.set_xlim(-.3,0.3)\n",
    "                cxx.set_ylim(1.5*sig.min(),2*sig.max())\n",
    "                #pl.axis('off')\n",
    "                fiz.savefig('/mnt/Data/ownCloud/Plots/Gerbil-plots/wvSample-'+str(item)+'.png',transparent=True,dpi=200)\n",
    "                cxx.cla()\n",
    "                bx.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7dfda6792ff9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     43\u001b[0m                 \u001b[0max4up\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1024\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m45000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'k'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.85\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m                 \u001b[0max4up\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                 \u001b[0mfiz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtransparent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m                 \u001b[1;31m#cxx.cla()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mbx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcla\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chenani/anaconda/lib/python2.7/site-packages/matplotlib/figure.pyc\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1563\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1565\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chenani/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_qt5agg.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chenani/anaconda/lib/python2.7/site-packages/matplotlib/backend_bases.pyc\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2230\u001b[0m                 \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2231\u001b[0m                 \u001b[0mbbox_inches_restore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2232\u001b[1;33m                 **kwargs)\n\u001b[0m\u001b[0;32m   2233\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2234\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chenani/anaconda/lib/python2.7/site-packages/matplotlib/backends/backend_agg.pyc\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_string_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mfilename_or_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png'"
     ]
    }
   ],
   "source": [
    "fiz = pl.figure(figsize=[4,6])\n",
    "bx = pl.Axes(fiz, [0., 0., 1., 1.])\n",
    "bx.set_axis_off()\n",
    "fiz.add_axes(bx)\n",
    "cxx = bx.twinx()\n",
    "pl.axis('off')\n",
    "wavelet=Morlet\n",
    "maxscale=3.05\n",
    "notes=64\n",
    "scaling=\"log\" #or \"linear\"\n",
    "#scaling=\"linear\"\n",
    "plotpower2d=True\n",
    "# set up some data\n",
    "Ns=2000\n",
    "for kk,item in enumerate(selG.index):\n",
    "    if kk==31:\n",
    "        for path in lfpPaths:\n",
    "            session = selG.session[item].split('0')[0]+selG.session[item].split('0')[1]\n",
    "            if path.find(selG.date[item])>0 and path.find(session)>0:\n",
    "                lfp = pkl.load(open(path,'rb'))\n",
    "                tP = selG['t_peak'][item]\n",
    "                t1 = tools.findNearest(lfp.timeAxis,tP-256)[0]\n",
    "                t2 = tools.findNearest(lfp.timeAxis,tP+256)[0]\n",
    "                sig = lfp.signal[t1:t2]\n",
    "                wsig = lfp.signal_white[t1:t2]\n",
    "                cw=wavelet(wsig,maxscale,notes,scaling=scaling)\n",
    "                scales=cw.getscales()     \n",
    "                cwt=cw.getdata()\n",
    "                # power spectrum\n",
    "                pwr=cw.getpower()\n",
    "                scalespec=np.sum(pwr,axis=1)/scales # calculate scale spectrum\n",
    "                # scales\n",
    "                y=cw.fourierwl*scales\n",
    "                for jj in range(pwr.shape[1]):\n",
    "                    pwr[:,jj] = np.convolve(pwr[:,jj],scsig.gaussian(15,15),'same')\n",
    "                bx.pcolormesh(np.linspace(-0.512,0.512,1024),y[::-1],(pwr),cmap = mycmps.magma)\n",
    "                bx.axhline(150,linewidth='1.5',color = 'w',linestyle='--')\n",
    "                bx.set_aspect('auto')\n",
    "                bx.set_xlim(-0.3,0.3)\n",
    "                bx.set_ylim(4,250)\n",
    "                #ax2up.axhline(sig.min(),alpha=0.001)\n",
    "                #ax2up.plot(np.linspace(-0.512,0.512,1024),sig,c='k',lw=0.9,alpha=0.000085)\n",
    "                ax4up.plot(np.linspace(-0.512,0.512,1024),sig+45000,c='k',lw=1.0,alpha=0.85)\n",
    "                ax4up.set_xlim(-0.3,0.3)\n",
    "                fiz.savefig('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png',transparent=True,dpi=600)\n",
    "                #cxx.cla()\n",
    "                bx.cla()\n",
    "    if kk==81:\n",
    "        for path in lfpPaths:\n",
    "            session = selG.session[item].split('0')[0]+selG.session[item].split('0')[1]\n",
    "            if path.find(selG.date[item])>0 and path.find(session)>0:\n",
    "                lfp = pkl.load(open(path,'rb'))\n",
    "                tP = selG['t_peak'][item]\n",
    "                t1 = tools.findNearest(lfp.timeAxis,tP-256)[0]\n",
    "                t2 = tools.findNearest(lfp.timeAxis,tP+256)[0]\n",
    "                sig = lfp.signal[t1:t2]\n",
    "                wsig = lfp.signal_white[t1:t2]\n",
    "                cw=wavelet(wsig,maxscale,notes,scaling=scaling)\n",
    "                scales=cw.getscales()     \n",
    "                cwt=cw.getdata()\n",
    "                # power spectrum\n",
    "                pwr=cw.getpower()\n",
    "                scalespec=np.sum(pwr,axis=1)/scales # calculate scale spectrum\n",
    "                # scales\n",
    "                y=cw.fourierwl*scales\n",
    "                for jj in range(pwr.shape[1]):\n",
    "                    pwr[:,jj] = np.convolve(pwr[:,jj],scsig.gaussian(15,15),'same')\n",
    "                bx.pcolormesh(np.linspace(-0.512,0.512,1024),y[::-1],(pwr),cmap = mycmps.magma)\n",
    "                bx.axhline(150,linewidth='1.5',color = 'w',linestyle='--')\n",
    "                bx.set_aspect('auto')\n",
    "                bx.set_xlim(-0.3,0.3)\n",
    "                bx.set_ylim(4,250)\n",
    "                #ax3up.axhline(sig.min(),alpha=0.001)\n",
    "                #ax3up.plot(np.linspace(-0.512,0.512,1024),sig,c='w',lw=0.9,alpha=0.000085)\n",
    "                ax5up.plot(np.linspace(-0.512,0.512,1024),sig+45000,c='k',lw=1.0,alpha=0.85)\n",
    "                ax5up.set_xlim(-0.3,0.3)\n",
    "                fiz.savefig('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample81.png',transparent=True,dpi=600)\n",
    "                #cxx.cla()\n",
    "                bx.cla()\n",
    "for kk,item in enumerate(selS.index):\n",
    "    if kk==51:\n",
    "        for path in lfpPaths:\n",
    "            session = selS.session[item].split('0')[0]+selS.session[item].split('0')[1]\n",
    "            if path.find(selS.date[item])>0 and path.find(session)>0:\n",
    "                lfp = pkl.load(open(path,'rb'))\n",
    "                tP = selS['t_peak'][item]\n",
    "                t1 = tools.findNearest(lfp.timeAxis,tP-256)[0]\n",
    "                t2 = tools.findNearest(lfp.timeAxis,tP+256)[0]\n",
    "                sig = lfp.signal[t1:t2]\n",
    "                wsig = lfp.signal_white[t1:t2]\n",
    "                cw=wavelet(wsig,maxscale,notes,scaling=scaling)\n",
    "                scales=cw.getscales()     \n",
    "                cwt=cw.getdata()\n",
    "                # power spectrum\n",
    "                pwr=cw.getpower()\n",
    "                scalespec=np.sum(pwr,axis=1)/scales # calculate scale spectrum\n",
    "                # scales\n",
    "                y=cw.fourierwl*scales\n",
    "                for jj in range(pwr.shape[1]):\n",
    "                    pwr[:,jj] = np.convolve(pwr[:,jj],scsig.gaussian(15,15),'same')\n",
    "                bx.pcolormesh(np.linspace(-0.512,0.512,1024),y[::-1],(pwr),cmap = mycmps.magma)\n",
    "                bx.axhline(150,linewidth='1.5',color = 'w',linestyle='--')\n",
    "                bx.set_xlim(-0.3,0.3)\n",
    "                bx.set_ylim(4,250)\n",
    "                #bx.set_axis_off()\n",
    "                ax2up.set_aspect('auto')\n",
    "                #ax4up.plot(np.linspace(-0.512,0.512,1024),sig,c='k',lw=0.9,alpha=0.000085)\n",
    "                ax2up.plot(np.linspace(-0.512,0.512,1024),sig,c='k',lw=1.0)\n",
    "                ax2up.set_xlim(-0.3,0.3)\n",
    "                #pl.axis('off')\n",
    "                fiz.savefig('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample51.png',transparent=True,dpi=600)\n",
    "                #cxx.cla()\n",
    "                bx.cla()\n",
    "    if kk==33:\n",
    "        for path in lfpPaths:\n",
    "            session = selS.session[item].split('0')[0]+selS.session[item].split('0')[1]\n",
    "            if path.find(selS.date[item])>0 and path.find(session)>0:\n",
    "                lfp = pkl.load(open(path,'rb'))\n",
    "                tP = selS['t_peak'][item]\n",
    "                t1 = tools.findNearest(lfp.timeAxis,tP-256)[0]\n",
    "                t2 = tools.findNearest(lfp.timeAxis,tP+256)[0]\n",
    "                sig = lfp.signal[t1:t2]\n",
    "                wsig = lfp.signal_white[t1:t2]\n",
    "                cw=wavelet(wsig,maxscale,notes,scaling=scaling)\n",
    "                scales=cw.getscales()     \n",
    "                cwt=cw.getdata()\n",
    "                # power spectrum\n",
    "                pwr=cw.getpower()\n",
    "                scalespec=np.sum(pwr,axis=1)/scales # calculate scale spectrum\n",
    "                # scales\n",
    "                y=cw.fourierwl*scales\n",
    "                for jj in range(pwr.shape[1]):\n",
    "                    pwr[:,jj] = np.convolve(pwr[:,jj],scsig.gaussian(15,15),'same')\n",
    "                bx.pcolormesh(np.linspace(-0.512,0.512,1024),y[::-1],(pwr),cmap = mycmps.magma)\n",
    "                #bx.imshow(pwr,aspect='auto',cmap = 'magma')\n",
    "                bx.axhline(150,linewidth='1.5',color = 'w',linestyle='--')\n",
    "                bx.set_xlim(-0.3,0.3)\n",
    "                bx.set_ylim(4,250)\n",
    "                #bx.set_axis_off()\n",
    "                ax3up.set_aspect('auto')\n",
    "                #cxx.axhline(sig.min(),alpha=0.001)\n",
    "                #cxx.plot(np.linspace(-0.512,0.512,1024),sig,c='w',lw=0.9,alpha=0.000085)\n",
    "                ax3up.plot(np.linspace(-0.512,0.512,1024),sig,c='k',lw=1.0,)\n",
    "                ax3up.set_xlim(-0.3,0.3)\n",
    "                #pl.axis('off')\n",
    "                fiz.savefig('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample33.png',transparent=True,dpi=600)\n",
    "                #cxx.cla()\n",
    "                bx.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-84527c16197d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0max4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'magma'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample81.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'magma'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample51.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chenani/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2288\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_imread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2289\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2290\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_imread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/chenani/anaconda/lib/python2.7/site-packages/matplotlib/image.pyc\u001b[0m in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1321\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png'"
     ]
    }
   ],
   "source": [
    "im = pl.imread('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample31.png')\n",
    "ax4.imshow(im,aspect='auto',cmap = 'magma')\n",
    "im = pl.imread('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample81.png')\n",
    "ax5.imshow(im,aspect='auto',cmap = 'magma')\n",
    "im = pl.imread('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample51.png')\n",
    "ax2.imshow(im,aspect='auto',cmap = 'magma')\n",
    "im = pl.imread('/home/chenani/ownCloud/Plots/Gerbil-plots/wvSample33.png')\n",
    "ax3.imshow(im,aspect='auto',cmap = 'magma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax2.set_xticks([0,1200,2400])\n",
    "ax2up.set_xticks([])\n",
    "ax2up.set_yticks([])\n",
    "#ax2up.set_axis_off()\n",
    "ax2.set_xticklabels([r'$-0.3$',r'$0$',r'$+0.3$'],fontsize=14)\n",
    "ax2.set_xlabel('Time (s)',fontsize=14)\n",
    "ax2.set_ylabel('Frequency (Hz)',fontsize=14)\n",
    "#ax2up.set_ylabel('Voltage (uV)',fontsize=14)\n",
    "ax2.set_yticks([600,1450,2200,3000])#,fontsize=14)\n",
    "ax2.set_yticklabels([r'200',r'150',r'100',r'50'],fontsize=14)\n",
    "#ax2p.set_axis_off()\n",
    "ax3.set_axis_off()\n",
    "#ax3up.set_axis_off()\n",
    "ax3up.set_xticks([])\n",
    "ax3up.set_yticks([])\n",
    "#ax3p.set_axis_off()\n",
    "#ax4.set_axis_off()\n",
    "ax4up.set_xticks([])\n",
    "ax4up.set_yticks([])\n",
    "#ax4up.set_axis_off()\n",
    "ax5.set_axis_off()\n",
    "#ax5up.set_axis_off()\n",
    "ax5up.set_xticks([])\n",
    "ax5up.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax4.cla()\n",
    "ax4up.cla()\n",
    "ax5.cla()\n",
    "ax5up.cla()\n",
    "ax2.cla()\n",
    "ax2up.cla()\n",
    "ax3.cla()\n",
    "ax3up.cla()\n",
    "#ax3p.cla()\n",
    "#ax4p.cla()\n",
    "#ax5p.cla()\n",
    "#ax1.cla()\n",
    "#ax16.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs2 = gridspec.GridSpec(12,12)\n",
    "gs2.update(left=0.55, right=0.98, hspace=0.05)\n",
    "ax10 = pl.subplot(gs2[:4, :6])\n",
    "ax11 = pl.subplot(gs2[:4, 6:])\n",
    "ax12 = pl.subplot(gs2[8:,:6])\n",
    "ax13 = pl.subplot(gs2[4:8,:6])\n",
    "ax14 = pl.subplot(gs2[4:8,6:])\n",
    "ax16 = pl.subplot(gs2[8:,6:])\n",
    "gs2.tight_layout(figure,rect=[0.51, 0.01, 0.99, 1])\n",
    "for axxx in [ax10,ax11,ax12,ax13,ax14,ax16,]:\n",
    "    axxx.xaxis.tick_bottom()\n",
    "    axxx.yaxis.tick_left()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rippDB = pd.read_pickle(animalPath+'RipplesTimeDB.pd')\n",
    "rippPSD = pkl.load(open(animalPath+'rippPSD.npArr','rb'))\n",
    "whiteRippPSD = pkl.load(open(animalPath+'whiteRippPSD.npArr','rb'))\n",
    "SWRsignal = pkl.load(open(animalPath+'rippSignal.npArr','rb'))\n",
    "ss = []\n",
    "for iii,item in enumerate(SWRsignal):\n",
    "    if item.size < 200:\n",
    "        SWRsignal[iii] = np.append(item,np.zeros(200 - item.size))\n",
    "        print iii\n",
    "    ss.append(item)\n",
    "ss = np.array(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rippDB = rippDB[rippDB.epoch=='sws']\n",
    "rippPSD= rippPSD[rippDB.index,:]\n",
    "ss = ss[rippDB.index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rcond = np.logical_and(rippDB.c ==1, rippDB.wc == 1)\n",
    "Gcond = np.logical_and(rippDB.c ==2, rippDB.wc == 2)\n",
    "cond12 = np.logical_and(rippDB.c ==1, rippDB.wc == 2)\n",
    "cond21 = np.logical_and(rippDB.c ==2, rippDB.wc == 1)\n",
    "p = np.array([0.0, 7.8125, 15.625, 23.4375, 31.25, 39.0625, 46.875, 54.6875, 62.5, 70.3125, 78.125,\n",
    " 85.9375, 93.75, 101.5625, 109.375, 117.1875, 125.0, 132.8125, 140.625, 148.4375, 156.25, 164.0625,\n",
    " 171.875, 179.6875, 187.5, 195.3125, 203.125, 210.9375, 218.75, 226.5625, 234.375, 242.1875, 250.0,\n",
    " 257.8125, 265.625, 273.4375, 281.25, 289.0625, 296.875, 304.6875, 312.5, 320.3125, 328.125, 335.9375,\n",
    " 343.75, 351.5625, 359.375, 367.1875, 375.0, 382.8125, 390.625, 398.4375, 406.25, 414.0625, 421.875,\n",
    " 429.6875, 437.5, 445.3125, 453.125, 460.9375, 468.75, 476.5625, 484.375, 492.1875, 500.0, 507.8125,\n",
    " 515.625, 523.4375, 531.25, 539.0625, 546.875, 554.6875, 562.5, 570.3125, 578.125, 585.9375, 593.75,\n",
    " 601.5625, 609.375, 617.1875, 625.0, 632.8125, 640.625, 648.4375, 656.25, 664.0625, 671.875, 679.6875,\n",
    " 687.5, 695.3125, 703.125, 710.9375, 718.75, 726.5625, 734.375, 742.1875, 750.0, 757.8125, 765.625,\n",
    " 773.4375, 781.25, 789.0625, 796.875, 804.6875, 812.5, 820.3125, 828.125, 835.9375, 843.75, 851.5625,\n",
    " 859.375, 867.1875, 875.0, 882.8125, 890.625, 898.4375, 906.25, 914.0625, 921.875, 929.6875, 937.5,\n",
    " 945.3125, 953.125, 960.9375, 968.75, 976.5625, 984.375, 992.1875, 1000.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0f904e1450>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.tsplot(rippPSD[Rcond.as_matrix(),:],time = p[:35],ax=ax10,color='#a6a5d3')\n",
    "sns.tsplot(rippPSD[Rcond.as_matrix(),:],time = p[:35],err_style=\"ci_bars\", interpolate=False,ax=ax10,condition='SWR',color='#a6a5d3')\n",
    "sns.tsplot(rippPSD[Gcond.as_matrix(),:],time = p[:35],ax=ax10,color='#f0b25c')\n",
    "sns.tsplot(rippPSD[Gcond.as_matrix(),:],time = p[:35],err_style=\"ci_bars\", interpolate=False,ax=ax10,condition='FGB',color='#f0b25c')\n",
    "sns.tsplot(ss[Rcond.as_matrix(),:],time = np.arange(-50,50,0.5),c='#a6a5d3',ax=ax11,condition='SWR')\n",
    "sns.tsplot(ss[Gcond.as_matrix(),:],time = np.arange(-50,50,0.5),c='#f0b25c',ax=ax11,condition='FGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1371 3073 450 13\n"
     ]
    }
   ],
   "source": [
    "print Rcond.sum(),Gcond.sum(),cond12.sum(),cond21.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x7f0fae99f710>,\n",
       " <matplotlib.text.Text at 0x7f0f8f521790>,\n",
       " <matplotlib.text.Text at 0x7f0f8fd0c710>,\n",
       " <matplotlib.text.Text at 0x7f0f8fbdb150>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax10.set_xlabel('Frequency (Hz)',fontsize=14)\n",
    "ax10.set_xticks([50,150,250])\n",
    "ax10.set_xticklabels([r'50',r'150',r'250'],fontsize=14)\n",
    "ax10.set_ylabel('PSD (a.u.)',fontsize=14)\n",
    "ax10.set_yticks([])\n",
    "ax11.set_ylabel('Voltage (uV)',fontsize=14)\n",
    "ax11.set_xlabel('Time (ms)',fontsize=14)\n",
    "ax11.set_xticks([-40,-20,0,20,40])\n",
    "ax11.set_xticklabels([r'-40',r'-20',r'0',r'20',r'40'],fontsize=14)\n",
    "ax11.set_ylim(-1800,1800)\n",
    "ax11.set_yticks([-1500,-500,500,1500])\n",
    "ax11.set_yticklabels([r'-1500',r'-500',r'500',r'1500'],fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax10.cla()\n",
    "ax11.cla()\n",
    "ax14.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistPlots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eventID = np.array(rippDB.shape[0]*['NA'])\n",
    "for iii,item in enumerate(Rcond.as_matrix()):\n",
    "    if item:\n",
    "        eventID[iii] = 'SWR'\n",
    "    if Gcond.as_matrix()[iii]:\n",
    "        eventID[iii] = 'FGB'\n",
    "rippDB['eventID'] = eventID\n",
    "rippDB['duration'] = (rippDB.t_f - rippDB.t_i)\n",
    "###Calculating Intervals\n",
    "iri = np.array(eventID.size*[np.nan])\n",
    "igi = np.array(eventID.size*[np.nan])\n",
    "Ridx = rippDB[Rcond].index\n",
    "Gidx = rippDB[Gcond].index\n",
    "for kk,idx in enumerate(Ridx):\n",
    "    if rippDB.session[Ridx[kk]]== rippDB.session[Ridx[kk-1]]:\n",
    "        iri[kk] = rippDB.loc[Ridx[kk]].t_peak - rippDB.loc[Ridx[kk-1]].t_peak\n",
    "for kk,idx in enumerate(Gidx):\n",
    "    if rippDB.session[Gidx[kk]]== rippDB.session[Gidx[kk-1]]:\n",
    "        igi[kk] = rippDB.t_peak[Gidx[kk]] - rippDB.t_peak[Gidx[kk-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    nan,    88.5,  6228.5, ...,     nan,     nan,     nan])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1371, 3073)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridx.size,Gidx.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x7f0faeacea50>,\n",
       " <matplotlib.text.Text at 0x7f0faec59450>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax13.set_yscale('log')\n",
    "#ax13.set_xscale('log')\n",
    "w = np.logical_not(np.isnan(iri))\n",
    "u = np.logical_not(np.isnan(igi))\n",
    "histiri,bins = np.histogram(iri[w],bins=np.arange(0,20000,50),normed=True)\n",
    "histigiAvg = np.zeros(bins.size-1)\n",
    "for i in range(5):\n",
    "    histigi,bins = np.histogram(np.random.choice(igi[u],iri[w].size),bins=np.arange(0,20000,50),normed=True)\n",
    "    histigiAvg += histigi\n",
    "histigiAvg = histigiAvg/2.0\n",
    "#histiei,bins = np.histogram(rippDB.iei,bins=bins,normed=True)\n",
    "ax13.scatter(bins[:-1],histiri,c='#a6a5d3',label='SWR')\n",
    "ax13.scatter(bins[:-1],histigiAvg,c='#f0b25c',label='FGB')\n",
    "ax13.set_xlabel('IEI (ms)',fontsize=14)\n",
    "ax13.set_ylabel('Normalized count',fontsize=14)\n",
    "ax13.legend()\n",
    "ax13.set_ylim(1e-6,0.01)\n",
    "ax13.set_xlim(-1000,10000)\n",
    "ax13.set_yticks([1e-5,1e-3])\n",
    "ax13.set_yticklabels([r'$10^{-5}$',r'$10^{-3}$'],fontsize=14)\n",
    "ax13.set_xticks([1e2,1e4])\n",
    "ax13.set_xticklabels([r'$10^2$',r'$10^4$'],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.020000000000000004, 0.019999999999999997)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "histigi.sum(),histiri.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax13.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.text.Text at 0x7f0f8f46e210>,\n",
       " <matplotlib.text.Text at 0x7f0f90781d90>,\n",
       " <matplotlib.text.Text at 0x7f0fb23dd350>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ax14.set_yscale('log')\n",
    "ax14.set_xscale('log')\n",
    "dBins = np.arange(50,5000,10)\n",
    "RDhist,bins = np.histogram(rippDB.duration[Rcond],dBins,normed=True)\n",
    "GDhist,bins = np.histogram(rippDB.duration[Gcond],dBins,normed=True)\n",
    "ax14.scatter(bins[:-1],RDhist,c='#a6a5d3',label='SWR')\n",
    "ax14.scatter(bins[:-1],GDhist,c='#f0b25c',label='FGB')\n",
    "ax14.legend()\n",
    "ax14.set_xlabel('Duration (ms)',fontsize=14)\n",
    "ax14.set_ylabel('Normalized count',fontsize=14)\n",
    "ax14.set_ylim(1e-5,1e-1)\n",
    "ax14.set_xlim(20,800)\n",
    "ax14.set_yticks([1e-4,1e-2])\n",
    "ax14.set_yticklabels([r'$10^{-4}$',r'$10^{-2}$'],fontsize=14)\n",
    "ax14.set_xticks([5e1,2e2,6e2])\n",
    "ax14.set_xticklabels([r'$50$',r'$200$',r'$600$'],fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax14.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sleep01', 'sleep02'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rippDB.session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rippDB.replace('sleep03','sleep02',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Rsws = rippDB[Rcond]['c']==1\n",
    "Rrem = rippDB[Rcond]['c']==1\n",
    "Gsws = rippDB[Gcond]['c']==2\n",
    "Grem = rippDB[Gcond]['c']==2\n",
    "RswsIEI = np.array([])\n",
    "RremIEI = np.array([])\n",
    "GswsIEI = np.array([])\n",
    "GremIEI = np.array([])\n",
    "for kk,idx in enumerate(rippDB[Rcond][Rsws].index):\n",
    "    prev = rippDB[Rcond][Rsws].index[kk-1]\n",
    "    if rippDB.session[idx] == rippDB.session[prev]:\n",
    "        RswsIEI = np.append(RswsIEI,rippDB.t_peak[idx]-rippDB.t_peak[prev])\n",
    "for kk,idx in enumerate(rippDB[Rcond][Rrem].index):\n",
    "    prev = rippDB[Rcond][Rrem].index[kk-1]\n",
    "    if rippDB.session[idx] == rippDB.session[prev]:\n",
    "        RremIEI = np.append(RremIEI,rippDB.t_peak[idx]-rippDB.t_peak[prev])\n",
    "for kk,idx in enumerate(rippDB[Gcond][Gsws].index):\n",
    "    prev = rippDB[Gcond][Gsws].index[kk-1]\n",
    "    if rippDB.session[idx] == rippDB.session[prev]:\n",
    "        GswsIEI = np.append(GswsIEI,rippDB.t_peak[idx]-rippDB.t_peak[prev])\n",
    "for kk,idx in enumerate(rippDB[Gcond][Grem].index):\n",
    "    prev = rippDB[Gcond][Grem].index[kk-1]\n",
    "    if rippDB.session[idx] == rippDB.session[prev]:\n",
    "        GremIEI = np.append(GremIEI,rippDB.t_peak[idx]-rippDB.t_peak[prev])\n",
    "\n",
    "IEImeans = []\n",
    "IEIstds = []\n",
    "IEIsems = []\n",
    "for item in [RswsIEI,RremIEI,GswsIEI,GremIEI]:\n",
    "    validx = np.logical_and(item>0,item<1e4)\n",
    "    IEImeans.append(item[validx].mean())\n",
    "    IEIstds.append(item[validx].std())\n",
    "    IEIsems.append(sem(item[validx]))\n",
    "#############################################\n",
    "#############################################\n",
    "#############################################\n",
    "Dmeans = [rippDB.duration[Rcond].mean(),\n",
    "          rippDB.duration[Rcond].mean(),\n",
    "          rippDB.duration[Gcond].mean(),\n",
    "          rippDB.duration[Gcond].mean()]\n",
    "Dstds = [ rippDB.duration[Rcond].std(),\n",
    "          rippDB.duration[Rcond].std(),\n",
    "          rippDB.duration[Gcond].std(),\n",
    "          rippDB.duration[Gcond].std()]\n",
    "Dsems = [sem(rippDB.duration[Rcond]),\n",
    "          sem(rippDB.duration[Rcond]),\n",
    "          sem(rippDB.duration[Gcond]),\n",
    "          sem(rippDB.duration[Gcond])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f91e46b80d0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#f,ax12 = pl.subplots(1,1)\n",
    "ax12.axvspan(0.02,0.1,ymin=0,ymax=IEImeans[0]/5000,color= '#a6a5d3',label='SWS-SWR')\n",
    "ax12.axvline(.06,ymin=(IEImeans[0]-IEIsems[0])/5e3,ymax=(IEImeans[0]+IEIsems[0])/5e3,linewidth=3,color='k')\n",
    "#ax12.axhline(((IEImeans[0]+IEIsems[0])/5e3),xmin=0.04,xmax=0.08)\n",
    "#################################\n",
    "ax12.axvspan(0.1,0.18,ymin=0,ymax=IEImeans[1]/5000,color= '#a6a5d3',alpha=0.5,label='REM-SWR')\n",
    "ax12.axvline(.14,ymin=(IEImeans[1]-IEIsems[1])/5000,ymax=(IEImeans[1]+IEIsems[1])/5000,linewidth=3,color='k')\n",
    "#ax12.axhline((IEImeans[1]+IEIsems[1])/5000,xmin=0.12,xmax=0.16)\n",
    "#################################\n",
    "ax12.axvspan(0.22,0.30,ymin=0,ymax=IEImeans[2]/5000,color= '#f0b25c',label='SWS-FGB')\n",
    "ax12.axvline(.26,ymin=(IEImeans[2]-IEIsems[2])/5000,ymax=(IEImeans[2]+IEIsems[2])/5000,linewidth=3,color='k')\n",
    "#ax12.axhline((IEImeans[2]+IEIsems[2])/5000,xmin=0.24,xmax=0.28)\n",
    "#################################\n",
    "ax12.axvspan(0.30,0.38,ymin=0,ymax=IEImeans[3]/5000,color= '#f0b25c',alpha=0.5,label='REM-FGB')\n",
    "ax12.axvline(.34,ymin=(IEImeans[3] - IEIsems[3])/5000,ymax=(IEImeans[3]+IEIsems[3])/5000,linewidth=3,color='k')\n",
    "#ax12.axhline((IEImeans[3]+IEIsems[3])/5000,xmin=0.32,xmax=0.36)\n",
    "#################################\n",
    "ax12.set_yticks([0.25,0.50,0.75])\n",
    "ax12.set_yticklabels([r'$1250$',r'$2500$',r'$3750$'],fontsize=14)\n",
    "ax12.set_xticklabels(['IEI','Duration'])\n",
    "ax12.set_ylabel('IEI (ms)',fontsize=14)\n",
    "######################\n",
    "ax12p = ax12.twinx()\n",
    "ax12p.axvspan(0.6,0.68,ymin=0,ymax=Dmeans[0]/150,color= '#a6a5d3')\n",
    "ax12p.axvline(.64,ymin=(Dmeans[0]-Dsems[0])/150,ymax=(Dmeans[0]+Dsems[0])/150,linewidth=3,color='k')\n",
    "#ax12p.axhline((Dmeans[0]+Dstds[0])/150,xmin=0.52,xmax=0.56)\n",
    "##################################\n",
    "ax12p.axvspan(0.68,0.76,ymin=0,ymax=Dmeans[1]/150,color= '#a6a5d3',alpha=0.5)\n",
    "ax12p.axvline(.72,ymin=(Dmeans[1]-Dsems[1])/150,ymax=(Dmeans[1]+Dsems[1])/150,linewidth=3,color='k')\n",
    "#ax12p.axhline((Dmeans[1]+Dstds[1])/150,xmin=0.6,xmax=0.64)\n",
    "##################################\n",
    "ax12p.axvspan(0.8,0.88,ymin=0,ymax=Dmeans[2]/150,color= '#f0b25c')\n",
    "ax12p.axvline(.84,ymin=(Dmeans[2]-Dsems[2])/150,ymax=(Dmeans[2]+Dsems[2])/150,linewidth=3,color='k')\n",
    "#ax12p.axhline((Dmeans[2]+Dstds[2])/150,xmin=0.72,xmax=0.76)\n",
    "##################################\n",
    "ax12p.axvspan(0.88,0.96,ymin=0,ymax=Dmeans[3]/150,color= '#f0b25c',alpha=0.5)\n",
    "ax12p.axvline(.92,ymin=(Dmeans[3]-Dsems[3])/150,ymax=(Dmeans[3]+Dsems[3])/150,linewidth=3,color='k')\n",
    "#ax12p.axhline((Dmeans[3]+Dstds[3])/150,xmin=0.78,xmax=0.82)\n",
    "\n",
    "ax12p.set_xlim(0,1)\n",
    "ax12p.set_yticks([0.2,0.4,0.6,0.8])\n",
    "ax12p.set_yticklabels([r'$30$',r'$60$',r'$90$',r'$120$'],fontsize=14)\n",
    "ax12p.set_xticks([0.225,0.725])\n",
    "ax12p.set_ylabel('Duration (ms)',fontsize=14)\n",
    "ax12.legend()\n",
    "#ax12.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax12.cla()\n",
    "ax12p.cla()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Rate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rr = pkl.load(open('/mnt/Data/data/Gerbils/popRateRipp.npArr','rb'))\n",
    "gg = pkl.load(open('/mnt/Data/data/Gerbils/popRateFGB.npArr','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.tsplot(rr,ax=ax16,color='#a6a5d3')\n",
    "sns.tsplot(rr,ax=ax16,color='#a6a5d3',err_style=\"ci_bars\", interpolate=False,condition='SWR')\n",
    "sns.tsplot(gg,ax=ax16,color='#f0b25c')\n",
    "sns.tsplot(gg,ax=ax16,color='#f0b25c',err_style=\"ci_bars\", interpolate=False,condition='FGB')\n",
    "ax16.set_xticks([-0,4.5,9])\n",
    "ax16.set_xticklabels([r'$-50$',r'$0$',r'$+50$'],fontsize=14)\n",
    "ax16.set_yticks([-0,0.8,1.6])\n",
    "ax16.set_yticklabels([r'$-0$',r'$0.8$',r'$1.6$'],fontsize=14)\n",
    "ax16.set_ylim(0,1.7)\n",
    "ax16.set_xlabel('Time (ms)',fontsize=14)\n",
    "ax16.set_ylabel(r'Population rate (S.D.)',fontsize=14)\n",
    "gs2.tight_layout(figure,rect=[0.52, 0.055, 0.99, 0.98])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax16.cla()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lots/Gerbil-plots/gFig-PNG-background.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ranksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWS-SWR vs. REM-SWR IEI p_value = 1.0\n",
      "SWS-SWR vs. SWS-FGB IEI p_value = 1.1944043036e-280\n",
      "SWS-FGB vs. REM-FGB IEI p_value = 1.0\n",
      "REM-SWR vs. REM-FGB IEI p_value = 1.1944043036e-280\n"
     ]
    }
   ],
   "source": [
    "rsTest = ranksums(RswsIEI,RremIEI)\n",
    "print 'SWS-SWR vs. REM-SWR IEI p_value = %s' %rsTest.pvalue\n",
    "rsTest = ranksums(RswsIEI,GswsIEI)\n",
    "print 'SWS-SWR vs. SWS-FGB IEI p_value = %s' %rsTest.pvalue\n",
    "rsTest = ranksums(GremIEI,GswsIEI)\n",
    "print 'SWS-FGB vs. REM-FGB IEI p_value = %s' %rsTest.pvalue\n",
    "rsTest = ranksums(RremIEI,GremIEI)\n",
    "print 'REM-SWR vs. REM-FGB IEI p_value = %s' %rsTest.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "RswsD = rippDB.duration[Rcond]\n",
    "RremD = rippDB.duration[Rcond]\n",
    "GswsD = rippDB.duration[Gcond]\n",
    "GremD = rippDB.duration[Gcond]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWS-SWR vs. REM-SWR Duration p_value = 1.0\n",
      "SWS-SWR vs. SWS-FGB Duration p_value = 2.8269332562e-07\n",
      "SWS-FGB vs. REM-FGB Duration p_value = 1.0\n",
      "REM-SWR vs. REM-FGB Duration p_value = 2.8269332562e-07\n"
     ]
    }
   ],
   "source": [
    "rsTest = ranksums(RswsD,RremD)\n",
    "print 'SWS-SWR vs. REM-SWR Duration p_value = %s' %rsTest.pvalue\n",
    "rsTest = ranksums(RswsD,GswsD)\n",
    "print 'SWS-SWR vs. SWS-FGB Duration p_value = %s' %rsTest.pvalue\n",
    "rsTest = ranksums(GremD,GswsD)\n",
    "print 'SWS-FGB vs. REM-FGB Duration p_value = %s' %rsTest.pvalue\n",
    "rsTest = ranksums(RremD,GremD)\n",
    "print 'REM-SWR vs. REM-FGB Duration p_value = %s' %rsTest.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
